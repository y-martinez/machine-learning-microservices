
+ dockerpath=ybrahinmartinez/project-microservices-udacity
+ kubectl run project-microservices-udacity --generator=run-pod/v1 --image=$dockerpath --port=80 --labels app=ml-udacity
pod/project-microservices-udacity created

+ kubectl wait pod/project-microservices-udacity --for=condition=Ready --timeout=-1s
pod/project-microservices-udacity condition met

+ kubectl get pods
NAME                            READY   STATUS    RESTARTS   AGE
project-microservices-udacity   1/1     Running   0          6h45m

+ kubectl port-forward project-microservices-udacity 5000:80
Forwarding from 127.0.0.1:5000 -> 80
Forwarding from [::1]:5000 -> 80
Handling connection for 5000

+ kubectl logs project-microservices-udacity  
 * Serving Flask app "app" (lazy loading)
 * Environment: production
   WARNING: Do not use the development server in a production environment.
   Use a production WSGI server instead.
 * Debug mode: on
 * Running on http://0.0.0.0:80/ (Press CTRL+C to quit)
 * Restarting with stat
 * Debugger is active!
 * Debugger PIN: 231-779-307
[2020-06-04 06:28:50,494] INFO in app: JSON payload: 
{'CHAS': {'0': 0}, 'RM': {'0': 9.575}, 'TAX': {'0': 296.0}, 'PTRATIO': {'0': 15.3}, 'B': {'0': 396.9}, 'LSTAT': {'0': 4.98}}
[2020-06-04 06:28:50,530] INFO in app: Inference payload DataFrame: 
   CHAS     RM    TAX  PTRATIO      B  LSTAT
0     0  9.575  296.0     15.3  396.9   4.98
[2020-06-04 06:28:50,547] INFO in app: Scaling Payload: 
   CHAS     RM    TAX  PTRATIO      B  LSTAT
0     0  9.575  296.0     15.3  396.9   4.98
[2020-06-04 06:28:50,553] INFO in app: The output prediction is: [20.35373177134412]
127.0.0.1 - - [04/Jun/2020 06:28:50] "POST /predict HTTP/1.1" 200 -